---
layout: default
---

# 嵌入式AI简报 (2021-10-15)：【】【】【】【】【】【】


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：

好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 三星：技术开发部门执行副总 Gitae Jeong 表示，半导体线宽微缩趋势遭遇许多技术上的困难导致进度放缓，眼前鳍式场效电晶体FinFET架构再度面临微缩限制，这也是三星积极开发 Gate All Around FET（GAA）架构，并且尽快在 3nm 工艺技术上导入多桥通道场效晶体管Multi-Bridge-Channel FET（MBCFET）技术最关键的原因。在 2022 年，三星会是世界上第一家量产 GAA 技术架构的半导体厂，第一个 3GAE（3nm Gate-All-Around Early）技术预计 2022 年量产；
- 三星特斯拉：三星将生产特斯拉的新型自动驾驶芯片。在今年1月，特斯拉已与三星合作研发一款用于全自动驾驶的5nm芯片，本次量产的应该就是这款芯片。5nm自动驾驶芯片性能是上一代的3倍。特斯拉现款芯片采用14nm制程工艺，同样由三星代工，单颗芯片算力可达72TOPS。特斯拉为自动系统配备两颗这样的芯片，系统综合算力达到144TOPS。
特斯拉第四代驾驶辅助硬件HW 4.0，也将基于5nm芯片开发。根据特斯拉以往硬件预装+软件后续迭代的开发思路，传感器性能也将直接瞄准L5级自动驾驶需求。
图片
马斯克在今年8月表示，HW 4.0的性能和安全性，都要比目前的HW 3.0更上一层楼。在采用HW 3.0的车型上，特斯拉自动驾驶系统比人类安全约300%，但HW 4.0可能会将这个数字提升到1000%。
根据马斯克的说法，特斯拉电动皮卡Cybertruck将成首款搭载HW 4.0的车型。
另外，特斯拉也在努力转向更复杂的AI框架，以满足高阶自动驾驶系统的需求。但从目前进度来看，5nm芯片最快可在2021年四季度进入小批量量产阶段，实体车应用至少要推迟到明年。

- 黑芝麻智能：黑芝麻智能宣布已经完成数亿美元的战略轮及C轮两轮融资。战略轮由小米长江产业基金、富赛汽车等国内产业龙头企业参与投资。。融资主要用于下一代高性能大算力自动驾驶平台的研发、人才引进、市场拓展和商业化。黑芝麻智能成立于2016年，专注于大算力自动驾驶计算芯片与平台等技术领域研发，核心技术包括图像/视频处理和感知理解算法等。在战略轮及C轮融资后，黑芝麻智能估值已近20亿美元，正式步入超级独角兽行列。据悉，C+轮融资目前也在顺利推进中。目前已基于两大核心自研IP：NeuralIQISP图像信号处理器及高性能深度神经网络算法平台DynamAI NN引擎，开发了多款自动驾驶芯片，以及自动驾驶计算平台。


> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  

- [苹果A15芯片评测：CPU和GPU提升惊人 | anandtech 半导体行业观察](https://mp.weixin.qq.com/s/K7l3ci3So7Dk4xkXW_4jlg)  
摘要：今年苹果在 A15 的公关方面有点奇怪，官方避免将新芯片与自己的 A14 进行任何世代比较。与过往不同的是，Apple 今年更喜欢与友商环境的比较中描述新 SoC；虽然这在 Mac 方面并不罕见，但在今年 iPhone 发布会上，情况比往年更加突出。关于 A15 的几个具体事实是，Apple 正在为其 CPU 使用新设计、更快的神经引擎、新的 4 核或 5 核 GPU（取决于 iPhone 版本），以及全新的显示pipeline 和视频媒体硬件块编码和解码，以及新的 ISP 改进以提高相机质量。  
本文作为对新 SoC 的初始评测，重点关注在新芯片的性能和效率指标：
    1. 频率提升：3.24GHz 性能核和 2.0GHz的效率内核；
    2. 巨型缓存：性能 CPU的 L2 增加到 12MB，SLC 增加到 32MB。Apple 的 SLC 可能是芯片能效的关键因素，能够将内存访问保持在同一个硅片上，而不是使用速度更慢、功率效率更低的 DRAM。我们已经看到更多 SoC 供应商采用了这些类型的最后一级缓存，但在 32MB 的情况下，新的 A15 使竞争对手的实现相形见绌，例如骁龙 888 上的 3MB SLC或 Exynos 2100 上估计的 6-8MB SLC ；
    3. CPU 微架构变化：缓慢的一年？苹果今年更温和的微架构变化的可能是几个原因造成的——苹果在 2019 年失去了他们在大型性能核心以及部分设计团队的首席架构师（Nuvia）（后来在今年早些时候被高通收购）。向 Armv9 的转变也可能意味着在设计上做了更多的工作，而疫情也可能导致了一些非理想的执行。等到明年的 A16，我们才能真正确定 Apple 的设计节奏是否已经放缓，或者这是否只是一个节点，或者只是下一个微架构发生更大变化之前的平静。
    4. GPU 性能：出色的 GPU，一般般的散热设计。在这一代的A15 芯片上，GPU的配置很有趣，这是苹果第一次在 iPhone 设备范围内对其 SoC 上的 GPU 配置进行功能分割。在微架构变化方面，新的 A15 GPU 似乎采用了与 M1 GPU 相同的双倍 FP32 吞吐量，似乎在现有的 FP32/双倍速率 FP16 ALU 旁边增加了额外的单元。增加的 32MB SLC 也可能对 GPU 带宽和hit-rates有很大帮助，因此这两个变化似乎是大幅增加的最明显的解释。
总体而言，正如前面第1/2点我们说道，等到明年的 A16，我们才能真正确定 Apple 的设计节奏是否已经放缓，或者这是否只是一个节点，或者只是下一个微架构发生更大变化之前的平静。  
- [“中国芯”新里程：壁仞科技首款高端通用GPU芯片交付流片 | 壁仞科技Birentech](https://mp.weixin.qq.com/s/nsiNyJZzsbCHza0Xo-zyMQ)  
摘要：通用智能芯片初创企业壁仞科技的首款通用GPU——BR100，于近日正式交付开始流片，预计将于明年面向市场发布。本次交付流片的通用GPU——BR100，性能参数直接对标当前国际最领先的同类产品，具有高算力、高通用性、高能效三大优势，采用先进的7纳米制程工艺，完全依托壁仞科技自主原创的芯片架构。  
搭载壁仞科技BR100芯片的系列通用计算产品，主要聚焦于人工智能训练和推理、通用运算等众多计算应用场景，将弥补人工智能应用的高速发展带来的巨大算力缺口，可广泛应用于包括智慧城市、公有云、大数据分析、自动驾驶、医疗健康、生命科学、云游戏等领域。

## 论文


- [2109.15099] [PPLCNet：CPU端强悍担当，吊打现有主流轻量型网络，百度提出CPU端的最强轻量型架构 | AIWalker](https://mp.weixin.qq.com/s/4QJaRIGFYzQG9UHstsECgQ)  
文章：https://arxiv.org/pdf/2109.15099.pdf  
代码: https://github.com/PaddlePaddle/PaddleClas  
摘要：自从ResNet以来，无论是轻量型还是高性能网络均重度依赖跳过连接、残差连接这种机制。反而像MobileNetV1这种非常简单模型的性能提升鲜少有学者进行深入研究。这篇文章是看不到创新的，但是工程性的梳理太令人钦佩了。在这样一个“每天都有几十篇AI相关paper”的时代，能这样静下来去深挖这些被忽视的细节并精心整理。  
本文提出一种基于MKLDNN加速的轻量CPU模型PP-LCNet，它在多个任务上改善了轻量型模型的性能。本文列举了一些可以提升模型精度且保持延迟几乎不变的技术，基于这些改进，所提PP-LCNet可以凭借同等推理速度大幅超过其他已有网络。 在图像分类任务方面，所提PP-LCNet在推理延迟-精度均衡方面大幅优于ShuffleNetV2、MobileNetV2、MobileNetV3以及GhostNet；在其他下游任务(如目标检测、语义分割等)，所提方案同样表现优异：
    1. Better activation function：采用H-Swish替换BaseNet中的ReLU，性能大幅提升，而推理速度几乎不变；
    2. SE modules at appropriate positions：当把SE置于模型的尾部时，它具有更好作用 。因此，我们仅将SE模块添加到接近网络尾部的模块 ，这种处理方式具有更好的精度-速度平衡。注：SE模块采用了与MobileNetV3相似的机制：SE中的两个激活函数分别为SE和H-Sigmoid；
    3. Larger convolution kernels：卷积核的尺寸通常会影响模型最终的性能，MixNet的作者分析了不同尺寸卷积对于网络性能的影响并提出了混合不同尺寸的卷积核，然而这种操作会降低模型的推理速度。我们尝试仅使用一个尺寸的卷积，并在低延迟&高精度情形下使用大尺度卷积核。类似SE模块的位置，在网络的尾部采用卷积核可以取得全部替换相近的效果。因此，我们仅在网络的尾部采用卷积；
    4. Larger dimensional conv layer after GAP：在本文所提PP-LCNet中，GAP后的输出维度比较小，直接添加分类层会有相对低的性能。为提升模型的强拟合能能力，我们在GAP后添加了一个1280维的卷积，它仅需很小的推理延迟即可取得更强的性能。  
- [1709.05943] [Fast YOLO：用于实时嵌入式目标检测 | 计算机视觉研究院](https://mp.weixin.qq.com/s/vaHqtdL6100brmfq0IBnyw)  
文章：https://arxiv.org/abs/1709.05943  
摘要：这篇文章翻译的不好，看看思想吧。  
提出的Fast YOLO框架分为两个主要部分：第一，优化的YOLOv2 backbone架构；第二，运动自适应推理，并非所有捕获的视频帧都包含被检物体，因此不需要对所有帧进行深度推理。对于每个视频帧，由带有参考帧的视频帧组成的图像，传递到1×1卷积层，该卷积层的结果是一个运动概率图，再送入运动自适应推理模块以确定是否需要推理来计算更新的类概率图。  
- [CPVR2021] [可以装在手机里的3D姿态估计，模型尺寸仅同类1/7，平均关节位置误差却只有5厘米 | 量子位](https://mp.weixin.qq.com/s/wQcvdFlu8jn-P6-Qxwyv1w)  
文章：https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Choi_MobileHumanPose_Toward_Real-Time_3D_Human_Pose_Estimation_in_Mobile_Devices_CVPRW_2021_paper.html  
代码：https://github.com/SangbumChoi/MobileHumanPose
摘要：三维姿态估计都平衡精度和计算成本，刚被 CPVR 2021 接受的论文中所提出的模型，MobileHumanPose却可以同时做到又小又好。其模型的尺寸，只有基于ResNet-50的模型的1/7，算力达到了3.92GFLOPS。且平均每关节位置误差（MPJPE），也只有大约5厘米。  
那么这一模型到底是如何在有限的算力下产生极佳性能的呢？这是一个从基本的编码器-解码器结构改良得来的模型。在编码器用于全局特征提取，而解码器进行姿态估计的基础架构上，研究团队对其主干网络、激活函数，以及Skip concatenation功能都进行了修改。研究团队选择的主干网络是 MobileNetV2 ，在其前四个倒置残差块（Residual Block）处修改了通道大小，获得了性能提升。此外，PReLU函数用于实现激活功能。但考虑到推理速度，团队使用Skip concatenation结构。这一结构能从编码器到解码器中导出低级别特征信号（Lowlevel feature signal），不会降低性能。  
- [移动端超分的磁悬浮，推理仅需10ms！港理工&达摩院开源超轻量超分网络ECB | 极市平台](https://mp.weixin.qq.com/s/wsA8XP4ej9lbFVRPB7E7CA)  
文章：https://www4.comp.polyu.edu.hk/~cslzhang/paper/MM21_ECBSR.pdf  
代码：https://github.com/xindongzhang/ECBSR  
摘要：本文是香港理工&达摩院张磊团队（https://www4.comp.polyu.edu.hk/~cslzhang/）在移动端超分 方面的工作，已被ACM-MM2021接收。本文将low-level领域知识与重参数思想进行了巧妙结合，提出了一种新颖的模块：Edge-oriented Convolution Block(ECB) 。基于ECB构建了超轻量型且性能同样突出的ECBSR，在x4任务输出为1080p，硬件平台为骁龙865DSP上：
    1. 当性能媲美SRCNN/ESPCN时，ECBSR-M4C8在移动端推理仅需10ms ，而SRCNN与ESPCN分别需要1583ms、26ms；
    2. 当性能媲美LapSRN时，ECBSR-M10C32在移动端推理仅需17ms ，而LapSRN则需要5378ms；
    3. 当性能媲美IMDN、EDSR以及CARN时，ECBSR-M16C64在移动端的推理仅需71ms ，而IMDN、EDSR与CARN的推理则分别为2782ms、527ms、170ms。



## 开源项目

- [OpenCV 4.5.4 发布 | OpenCV团队](https://mp.weixin.qq.com/s/PEOxwkxEWanxlDu4PS9kNg)
摘要：重要改进：GSoC 2021结束了，11个项目的以下成果目前已经合入OpenCV 4.5.4（main repo和opencv_contrib）:
DNN模块8位量化功能和导入ONNX量化模型功能
改进的Julia语言绑定
语音识别示例
OpenCV DNN对RISC-V的优化（中科院软件所贡献）
Universial Intrinsics和parallel_for_使用教程

DNN模块：
改进layers和activations，支持更多模型
GRU, CumSum, Max, Min, ExpandDims
修复卷积的非对称填充
修复Unsqueeze (ONNX opset 13)
修复OpenCL核的几个内存填充问题
实现TextRecognitionModel中的CTC前缀束搜索解码
增加SoftNMS
Intel推理引擎后端（OpenVINO ）：
增加OpenVINO 2021.4.1 LTS release的支持
增加对非FP32输出或1D输出模型的支持

G-API模块：
【OpenCV G-API持续改进提升中，对G-API全面了解，欢迎参加10月12日的OpenCV Webinar 9：Understanding OpenCV G-API: Background, Current status, and Future plans】
其他贡献：
objdetect模块中增加基于深度学习的人脸检测（libfacedetection）和人脸识别（北京邮电大学贡献）
恢复LineSegmentDetector (LSD)实现
增加numpy.ndarray的cv.Mat接口，以处理C++算法中传入3D数组出现的问题
纯Python模块和函数的OpenCV扩展支持
cv::Mat增加gdb pretty-printer
iOS和macOS增加Quicklook
增加radon checkerboard新类型的生成
DNN sample中增加PaddlePaddle人体分割模型支持（百度贡献）
更多详细信息请参考：
https://github.com/opencv/opencv/wiki/ChangeLog#version454

## 博文


- [深度学习编译系列之算子编译IR转换
小P家的ID 000009 商汤学术
https://mp.weixin.qq.com/s/oKBXuKGwhS9nYIUQa6yK0g
这篇小文给出了对于深度学习编译器在一种长尾算子代码生成场景中IR stack的讨论。虽然单个长尾算子在整个神经网络中可能耗时比例较小，但是神经网络中可能包含数十个甚至数百个长尾算子，并且在未来这种需求也在不断地被创造。 



因此，基于编译手段，不断增强支持不同类型的算子翻译，具有重要意义。当然，计算型算子和访存型算子有着不同的特征，计算型算子需要注意计算 pattern 的翻译，并需要满足形状信息约束，而访存型算子则需要注意 访存 pattern 的翻译，有些操作潜在囊括于 python 复杂的语法定义中，这时便需要在深度学习编译器中对应设计 IR 以支持 IR lowering 以及代码生成流程。 
