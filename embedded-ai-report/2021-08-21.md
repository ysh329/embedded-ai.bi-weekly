---
layout: default
---

# 嵌入式AI简报 (2021-08-21)：


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：

好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 英伟达：2021Q2创下 65.1 亿美元的纪录，较2021年同期增长 68%，较Q1增长 15%，**公司的游戏、数据中心部门推动了净利润同比增长282%，以及专业视觉平台均创下收入纪录**；
- 台积电：**市值超越腾讯，成亚洲市值最高的公司**。截至8月18日上午亚洲时段的数据，台积电目前在亚洲公司中以超过 5380 亿美元的市值位居榜首。腾讯和阿里巴巴分别以超过 5360 亿美元和 4720 亿美元分别占据市值第二和第三的位置；
- 比亚迪半导体：**上市被“中止”，原因是被律所“连坐”。比亚迪半导体用不到短短两个月迅速完成两轮融资。其中，5月26日宣布完成的A轮融资（19亿元）和6月15日宣布完成的A+轮融资（8亿元），中间仅相距20天。估值超100亿**。根据招股书，其拥有功率半导体（最核心，近三年来营收占比徘徊在30%）、智能控制IC、智能传感器、光电半导体等产品的研发设计能力以及全套产线；
- 高通：推出全球首个由5G和AI赋能的无人机平台和参考设计——**Qualcomm Flight RB5 5G平台，能够以超低功耗支持高性能异构计算，提供高能效边缘侧推理**；由高通创投投资的格科微有限公司（简称：“格科微”，股票代码：688728）登陆科创板。创立于2003年，业务为CMOS图像传感器和显示驱动芯片的研发、设计和销售。**未来，格科微还将通过自建部分12英寸BSI晶圆后道制造产线、12英寸晶圆制造中试线、部分OCF制造及背磨切割产线的方式，巩固产能保障力度，提升在高阶产品领域的研发能力和研发速度，并加强对供应链产能波动风险的抵御能力**；
- 高通：推出全球首个由5G和AI赋能的无人机平台和参考设计——Qualcomm Flight RB5 5G平台。
- 商汤：**传言将启动IPO，计划未来几周在港交所提交IPO申请**。若属实，将成为继旷视科技、云知声、依图科技后，又一家上市的人工智能公司；
- 燧原：**投资成立半导体公司，入局集成电路芯片设计和服务**。此前燧原先后发布两代AI训练芯片，并与腾讯基于业务真实场景开展了深入合作，其执行力和落地能力已得到了证明；
- 爱芯科技：完成**数亿元A+轮融资总金额达数亿元人民币**，韦豪创芯、美团联合领投。成立于2019年5月，**专注于研发高性能、低功耗的人工智能视觉处理芯片，并自主开发面向推理加速的神经网络处理器**。其自主研发的第一颗AI芯片——AX630A已达成量产状态，这一针对边缘侧、端侧应用的人工智能视觉芯片，在算法与硬件的深度结合下，可提供高品质的视频图像质量，支持物体检测、人脸识别等多种AI视觉任务，应用前景十分广阔。继AX630A进入量产后，爱芯科技自主研发的第二颗芯片日前也已回片并成功点亮。未来，爱芯科技将在保障AX630A现货供应的基础上，持续研发更多具有差异化的产品，适应端侧与边缘侧复杂的应用环境，赋能各行各业实现智慧化发展，真正实现“AI改变生活”；
- 三星：Exynos 2200将配备6核心的**RDNA2架构GPU，其GPU测试能领先骁龙888达40%，但由于原材料供应、产能、工艺等方面的限制，可能要在大批产品上放弃搭载该芯片的想法**。下一代旗舰级平板产品Galaxy Tab S8/S8+/S8 Ultra可能将转而搭载高通下一代平台骁龙898芯片；
- AMD：Mercury Research 的最新数据显示，今年 2 季度，AMD 已成功占据 x86 处理器市场的 22.5% 份额。这是自 2007 年以来的最高纪录、并且接近 2006 年 25.3% 的历史峰值。不过英特尔的份额依然高达 77.5%，而威盛（VIA）等少数 x86 处理器厂家的全球份额几乎可以忽略不计。这份报告还提供了更细致的市场划分统计，可知 AMD 台式 CPU 的份额略有下滑，从 2021 年 1 季度的 19.3%、降到了 2 季度的略高于 17% ；
- Intel：**发布基于 Xe HPG 微架构的高性能显卡 Arc** ，并融合 Xe LP、HP 和 HPC 微架构的优势，**专为消费端打造**，涵盖硬件、软件和服务三方面。代号为 Alchemist 的第一代 Arc 产品将采用基于硬件的光线追踪和A.I.驱动的超级采样，为 DirectX 12 Ultimate 提供全面支持，并**将于 2022Q1 上市**；
- 轻舟智航：继2021年年初完成A轮融资之后，**无人驾驶头部公司轻舟智航又获得了1亿美元A+轮融资**。该公司2019年3月成立于硅谷，当时自动驾驶RoboTaxi、货运、低速物流车等等都已经形成明显头部阵营。**该笔融资的落地能够加速轻舟自动驾驶“超级工厂”的落地。为实现自动驾驶的商业化及规模化**；
- pony.ai: 传小马智行暂缓赴美上市。公司回应称：公司并未确认过上市计划抑或上市时间线，已经暂缓了通过SPAC以120亿美元估值赴美上市的计划。知情人士称，这家由丰田汽车支持的初创公司将寻求通过私募融资，估值为120亿美元；
- 壁仞科技：**前AMD全球副总裁李新荣（Allen Lee）先生加入壁仞科技**，出任联席CEO，专注组织，管理及产品设计端。李新荣先生在GPU领域拥有超过30年的丰富经验，在AMD就职15年中，一手构建规模数千人的研发团队，并实现了团队研发能力从单项到覆盖“端到端”完整项目流程的大突破；

> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  


- [来自莱斯大学的初创公司ThirdAI：致力于AI的通用CPU算法，干掉GPU | 半导体行业观察](https://mp.weixin.qq.com/s/BayDiRU26soehbdw_1c1CA)  
摘要：致力于降低 AI 深度学习成本的初创公司 ThirdAI ，利用其算法和软件创新，使通用中央处理器 (CPU) 比用于训练大型神经网络的图形处理单元更快。他们推出了 SLIDE（Sub-Linear Deep Learning Engine：次线性深度学习引擎），这是一种部署在通用 CPU 上的算法，生成可以对抗 GPU 的主导地位。  
**SLIDE 提供的结果比可用的最佳 Tensorflow GPU 硬件快 3.5 倍，性能比 Tensorflow CPU 高 10 倍**。 **SLIDE 使用采样哈希表，特别是修改后的局部敏感哈希（LSH），来快速查询神经元 ID 以进行激活，而不是逐个矩阵计算整个网络矩阵**。  
**通过使用多核 CPU 处理和优化——以及局部敏感散列 (LSH) 和自适应丢失——SLIDE 实现了，无论批量大小如何，都可以做到 O(1) 或恒定时间的复杂度**，正是得益于这样的设计，该公司获得了Neotribe Ventures、Cervin Ventures 和 Firebolt Ventures的投资，该投资将用于雇用更多员工并投资于计算资源。  
- [谷歌安卓上新功能：用脸就能控制手机 | 智东西](https://mp.weixin.qq.com/s/hWQoa5uh7YSpoYxQhfP4gA)  
摘要：谷歌最近更新了其安卓无障碍（辅助功能）套件（Android Accessibility Suite），其中的“开关/切换访问（Switch Access）”功能列表增加了“摄像头开关（Camera Switch）”功能。开关访问功能用于设置用户操控手机的快捷方式，比如通过蓝牙、USB连接，用户可以设置无线耳机、外接键盘等设备如何操控手机，现在谷歌又增加一种“非接触式”操控方式——用脸。  
有了这一功能，用户可以用张嘴、微笑、扬眉、向左看、向右看和向上看这6种表情来操控手机，执行“选择”、“下一步”、“返回”等十几种操作。  
- [三星下一代手机芯片由AI来设计，EDA行业老大提供技术 | 量子位](https://mp.weixin.qq.com/s/oHz8y3LkR2glGHw6kL9Aow)  
摘要：据外媒《连线》的报道，三星将使用新思科技（Synopsys）提供的AI功能——DSO.ai——来设计下一代Exynos处理器。  
新思科技是全球最大的芯片设计软件（EDA）供应商之一，这家公司的董事长表示，DSO.ai是第一个用于处理器设计的商业AI软件。DSO.ai对设计速度的提升效果明显，新思科技说，这项工具在一些情况下将芯片频率提高了18%，功耗降低了21%，同时将工程时间从六个月缩短到了一个月。  
而且AI还会不断自学提高能力，从一个项目中获得的经验会被保留下来，用于未来的芯片设计工作。一家EDA厂商Cadence也与近期推出了AI设计工具。国外芯片软件技术遍地开花，而中国芯片厂商则面临着尴尬的局面。由于市场上三大EDA软件公司Synopsys、Cadence、Mentor均来自美国，且占据着中国95%的市场份额。  
- [UC伯克利博士尤洋回国创业，求学期间破ImageNet纪录！已获超千万种子轮融资 | 量子位](https://mp.weixin.qq.com/s/gKGdog38zjx4HUU-eYzqVQ)  
摘要：尤洋，是LAMB优化器的提出者，曾成功将预训练一遍BERT的时间，从原本的三天三夜一举缩短到一个多小时。英伟达官方GitHub显示，LAMB 比 Adam 优化器可以快出整整 72 倍。　　
尤洋已在UC伯克利获得了博士学位，目前**回国并创立潞晨科技。公司主营业务包括分布式软件系统、大规模人工智能平台以及企业级云计算解决方案**。地点在北京中关村，目前已经获得由创新工场和真格基金合投的超千万元种子轮融资。
单纯地堆硬件，并不能解决所有问题。一方面，当硬件数量达到一定量后，堆机器无法带来效率上的提升；另一方面，中小企业往往没有足够的资金支持如此大规模的硬件部署。因此，优化技术成为了绝佳选择。**潞晨科技就是旨在打造一个高效率低耗能的分布式人工智能系统。它可以帮助企业在最大化提升人工智能部署效率的同时，还能将部署成本最小化**。而且潞晨打造的系统是一个通用系统，对大部分超大模型都有效。就目前的Transformer应用而言，该系统在同样的硬件上相对业界最好的系统，可以提升2.32倍的效率。以上他们打造的通用系统，依旧离不开LAMB（Layer-wise Adaptive Moments optimizer for Batch training）方法。　　
尤洋他们在研究中发现，在不改变硬件设置的情况下，**能耗主要来自于数据移动。数据移动包括集群内服务器之间的通讯、GPU与CPU之间的通讯、CPU与磁盘的通讯等等。为此，他们还实现了一套基于通讯避免算法的系统**。可以在不增加计算量的情况下有效减少数据移动量，从而减少能耗。　　
- [OpenAI CLIP模型袖珍版，24MB实现文本图像匹配，iPhone上可运行 | 机器之心](https://mp.weixin.qq.com/s/xfHTaHS_fl1556A5aNSDcQ)  
摘要：最近，PicCollage 公司在自己的内容产品上对 CLIP 模型进行了测试，并获得满意的性能。350MB 的FP32 原始模型（可称为 teacher 模型）蒸馏后降为 48MB（student 模型）。**在单个 P100 GPU 上训练了数周后，将 48MB 大小的 FP32 student 模型转换成了 CoreML 格式的 FP16 24MB 大小的模型，精度为 FP16，性能变化几乎可以忽略不计，蒸馏后的模型可以在 iPhone 等 IOS 设备上运行**。  


## 论文

- [Only Train Once：微软、浙大等研究者提出剪枝框架OTO，无需微调即可获得轻量级架构 | 机器之心](https://mp.weixin.qq.com/s/_uUtDFL7lhxTkVR_Sl-VPQ)  
链接：https://arxiv.org/pdf/2107.07467.pdf  
摘要：来自微软、浙江大学等机构的研究者提出了一种 one-shot DNN 剪枝框架，无需微调即可从大型神经网络中得到轻量级架构，在保持模型高性能的同时还能显著降低所需算力。该研究的主要贡献概括如下：  
    1. One-Shot 训练和剪枝。研究者提出了一个名为 OTO（Only-Train-Once）的 one-shot 训练和剪枝框架。它可以将一个完整的神经网络压缩为轻量级网络，同时保持较高的性能。OTO 大大简化了现有剪枝方法复杂的多阶段训练 pipeline，适合各种架构和应用，因此具有通用性和有效性。  
    2. Zero-Invariant Group（ZIG）。研究者定义了神经网络的 zero-invariant group。如果一个框架被划分为 ZIG，它就允许我们修剪 zero group，同时不影响输出，这么做的结果是 one-shot 剪枝。这种特性适用于全连接层、残差块、多头注意力等多种流行结构。  
    3. 新的结构化稀疏优化算法。研究者提出了 Half-Space Stochastic Projected Gradient（HSPG），这是一种解决引起正则化问题的结构化稀疏的方法。研究团队在实践中展示并分析了 HSPG 在促进 zero group 方面表现出的优势（相对于标准近端方法）。ZIG 和 HSPG 的设计是网络无关的，因此 OTO 对于很多应用来说都是通用的。  
实验结果。利用本文中提出的方法，研究者可以从头、同时训练和压缩完整模型，无需为了提高推理速度和减少参数而进行微调。在 VGG for CIFAR10、ResNet50 for CIFAR10/ImageNet 和 Bert for SQuAD 等基准上，该方法都实现了 SOTA 结果。
- [MicroNets：更小更快更好的MicroNet，三大CV任务都秒杀MobileNetV3 | 我爱计算机视觉](https://mp.weixin.qq.com/s/8Veob1WRd3S-CnOdeedfRQ)  
摘要：本文旨在以极低的计算成本解决性能大幅下降的问题。**作者发现有两个因素是可以有效提高精度的，分别是：稀疏连通性和动态激活函数**。前者避免了网络宽度的大幅度缩减的危害，而后者则减轻了网络深度缩减的危害。这其中，作者首先证明了在给定的计算预算的情况下，**降低节点连通性以扩大网络宽度**为提供了一个很好的权衡。其次，依赖于**改进的层非线性来弥补减少的网络深度**，这决定了整个网络的非线性 。这两个因素激发了更有效卷积和激活函数的设计。  
技术上来讲，作者提出的微分解卷积（micro-factorized convolution），它将卷积矩阵分解成低秩矩阵，以将稀疏连通性整合到卷积中，即Micro-Factorized convolution，其**通过在pointwise和depthwise卷积上的低秩近似来实现通道数和输入/输出连接之间的平衡**。  
而新的动态激活函数，称为Dynamic Shift Max，**通过最大化输入特征图和圆形通道位移之间的多次动态融合来提高非线性，动态地融合了连续的通道组，增强节点连接性和非线性，以弥补深度的减少**。  
基于这两个操作，作者提出一个新的网络系列：MicroNet，在低FLOP状态下，它取得了显著的性能提高。MicroNet对三个CV任务（图像分类、目标检测和人体姿态估计）都实现了明显的改进。例如，在12M FLOPs的约束下，MicroNet在ImageNet分类上达到了59.4%的Top-1准确率，比MobileNetV3高出9.6%。  


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [mindspore-ai/mindspre: 端侧AI框架-MindSpore1.3 Lite的大更新 | MindSpore](https://mp.weixin.qq.com/s/zycfyM4XslTJptBzAN9amQ)  
摘要：上半年MindSpore陆续发布了1.2和1.3两个版本，端侧Lite这一块其实增加了很多大特性，前面没有太多宣传，这次统一把MindSpore Lite最新版本的主要新增能力给大家介绍一下。  
这个版本中全新的南向自定义能力，Delegate机制，针对微处理器的Micro方案，新增支持NNIE/NVIDIA GPU等硬件推理，完善控制流，支持流式执行，支持稀疏编码，端云联邦学习、性能更高的算子库等，给端侧AI带来更多的全新体验。下面就带大家快速浏览这两个版本的关键特性。


## 博文


- [计算图替代——一种DNN框架计算图优化方法 | Adlik 深度学习推理工具链](https://mp.weixin.qq.com/s/vcVJ3bYLoCv2UTgHzBjLuw)  
标题：Optimizing DNN Computation Graph using Graph Substitutions  
链接：http://www.vldb.org/pvldb/vol13/p2734-fang.pdf  
摘要：在DNN中每一回合的推理或训练中的每一次迭代通常可以表示为计算图，通过计算图优化可以提高DNN训练和推理的速度。目前主流的框架Tensorflow供了图优化器的API、TVM采用Op Fusion在内的多种计算图优化手段进行加速计算。  
**本文将主要介绍computation graph substitution优化方法**。计算图**替代就是找到另外一个计算图在功能上等效替代当前的计算图，在替代的同时可以减小计算时间以及计算量**。  
从现有的论文来看，**计算图替代可以起到一定的优化计算效果，需要将图形级和算子级优化结合起来**。这种联合优化具有挑战性，因为这两个问题都涉及到庞大且复杂的搜索空间，而一个级别的优化会影响另一个级别的搜索空间。未来研究方向应该是在减小搜索空间的同时进行最大限度的图替代，并且将计算图替代优化与其他优化方法结合，这样会给DNN框架优化计算带来最大的收益。 
