---
layout: default
---

# 嵌入式AI简报 (2022-06-30)：  


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


> 导读：【新闻】；【论文】；【开源】；【博文】。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：



> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  



## 论文  



## 开源项目



## 博文

- [Tenstorrent芯片架构浅谈 | Adlik 深度学习推理工具链](https://mp.weixin.qq.com/s/y-P1X-QeLjozC7jvEeAolA)  
摘要：近年市场上的AI芯片层出不穷，根源上还是算法与应用均处于高速迭代，计算硬件底座自然需要不断更新。其中芯片公司Tenstorrent的芯片架构别具一格，本文尝试一探究竟。  
Tenstorrent共设计出3款芯片，其中Jawbridge是一款小型测试芯片，Grayskull和Wormhole则是对外商用芯片，可覆盖训练和推理场景。Tenstorrent的芯片架构设计目标是解决模型在训练或推理时无法高效灵活扩展（scale out）的问题，提出2个核心技术点：
    1. 摒弃传统的核间共享式内存架构，采用Multicore Private Memory Model：芯片重点在硬件层面和软件层面分别加强了数据通信能力。在硬件层自研片上互联Network on Chip(NoC), NoC是2D双向环路结构；
    2. 动态执行：
        2.1 运行时数据压缩，以设计较小容量的private memory，在芯片内多核间及芯片间的数据通信量也随之降低，进而从整体上可以获得更高的性能功耗比。另外，Packet Manager还可以处理reshape/flatten等tensor形状变换操作，且该操作可以与Compute Engine并行执行，时间上可以overlap；
        2.2 条件执行：片上的逻辑控制单元和计算单元均可以高效运行，避免了CPU fallback的问题，基于稀疏门控专家混合模型，可通过门口网络实现只激活模型的部分结构，在增加模型容量和能力下不会成比例增加计算量；
        2.3 稀疏计算：支持常规的对权重进行稀疏化之外，还支持对激活值进行分块稀疏，进而降低计算量；
        2.4 动态混合精度：可以在运行时或AOT阶段设置每个算子的计算精度。该技术在主流深度学习框架中都有实现，因此个人认为这项技术并无特色。
Tenstorrent通过软硬协同设计方式，将数据并行和模型并行的部分功能实现下沉到硬件层，有效解决了横向扩展问题，这样就可以替代当前主流深度学习框架在分布式实现方面的大量编码工作，进而降低了深度学习框架的开发和使用门槛。同时，硬件的变化并没有降低软件栈的通用性，其软件栈支持PyTorch等主流框架。另一方面，芯片具有高度模块化，多个芯片可通过标准以太网端口连接在一起，进而扩展成大型AI网络。由于芯片内已集成NoC，因此这种扩展并不需要额外的交换机，因此扩展灵活度很高。       
        
    
