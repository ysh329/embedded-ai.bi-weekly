---
layout: default
---

# 嵌入式AI简报 (2022-06-30)：  


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


> 导读：【新闻】；【论文】；【开源】；【博文】。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 台积电：2nm N2技术路线图亮相，计划于 2025 年投入生产，承诺让芯片设计人员在同功率和晶体管数量下将性能提升 10% 至 15%，或在相同频率和复杂度下将功耗降低 25% 至 30%。广泛使用 EUV 光刻技术，并引入了 GAAFET（台积电称之为纳米片晶体管）以及背面供电；
预计台南的生产中心再建四座价值 100 亿美元的工厂，用于制造 3 nm芯片，覆盖 Apple SoC、 A 系列芯片；

台积电周五宣布，计划到2025 年 转向2 纳米芯片的量产。
Imagination：GPU获得ADAS和HMI应用的ISO 26262功能安全认证；
- AMD：支持芯片定制，向第三方Chiplet打开大门。允许客户如早先的索尼，微软游戏主机，可以在紧凑的芯片封装中实现多个裸片（也称为chiplet或compute tiles ）。AMD 已经在使用tiles，但现在欢迎第三方制造加速器或汽车等其他芯片，以将其与 x86 CPU 和 GPU ，AI加速器一起包含在 其2D 或 3D 封装中；
三星：疑抢购EUV光刻机，副董事长六月中旬会见了 ASML CEO 讨论了高端芯片设备合作；


> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  



## 论文  

- [meituan/YOLOv6: YOLOv6——精度与速度远超 YOLOv5 和 YOLOX 的新框架 | 美团技术团队](https://mp.weixin.qq.com/s/RrQCP4pTSwpTmSgvly9evg)  
代码：https://github.com/meituan/YOLOv6  
摘要：本文介绍了美团视觉智能部在目标检测框架方面的优化及实践经验，针对 YOLO 系列框架，在训练策略、主干网络、多尺度特征融合、检测头等方面进行了思考和优化，设计了新的检测框架-YOLOv6，初衷来自于解决工业应用落地时所遇到的实际问题：
    1. 更高效的 Backbone 和 Neck ：受到硬件感知神经网络设计思想的启发，基于 RepVGG style 设计了可重参数化（其结构在训练时有多分支拓扑，实际部署时可融合为单个 3x3 卷积）、更高效的骨干网络 EfficientRep Backbone 和 Rep-PAN Neck；
    2. 优化设计了更简洁有效的 Efficient Decoupled Head，维持精度同时，降低了一般解耦头带来的额外延时开销；
    3. 训练策略：采用Anchor-free 无锚范式，同时辅以 SimOTA 标签分配策略以及 SIoU 边界框回归损失来进一步提高检测精度。
在工业界常用的尺寸模型中：YOLOv6-nano 在 COCO 上精度可达 35.0% AP，在 T4 上推理速度可达 1242 FPS；YOLOv6-s 在 COCO 上精度可达 43.1% AP，在 T4 上推理速度可达 520 FPS。在部署方面，YOLOv6 支持 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等不同平台的部署，极大地简化工程部署时的适配工作。  



## 开源项目



## 博文

- [Tenstorrent芯片架构浅谈 | Adlik 深度学习推理工具链](https://mp.weixin.qq.com/s/y-P1X-QeLjozC7jvEeAolA)  
摘要：近年市场上的AI芯片层出不穷，根源上还是算法与应用均处于高速迭代，计算硬件底座自然需要不断更新。其中芯片公司Tenstorrent的芯片架构别具一格，本文尝试一探究竟。  
Tenstorrent共设计出3款芯片，其中Jawbridge是一款小型测试芯片，Grayskull和Wormhole则是对外商用芯片，可覆盖训练和推理场景。Tenstorrent的芯片架构设计目标是解决模型在训练或推理时无法高效灵活扩展（scale out）的问题，提出2个核心技术点：
    1. 摒弃传统的核间共享式内存架构，采用Multicore Private Memory Model：芯片重点在硬件层面和软件层面分别加强了数据通信能力。在硬件层自研片上互联Network on Chip(NoC), NoC是2D双向环路结构；
    2. 动态执行：
        2.1 运行时数据压缩，以设计较小容量的private memory，在芯片内多核间及芯片间的数据通信量也随之降低，进而从整体上可以获得更高的性能功耗比。另外，Packet Manager还可以处理reshape/flatten等tensor形状变换操作，且该操作可以与Compute Engine并行执行，时间上可以overlap；
        2.2 条件执行：片上的逻辑控制单元和计算单元均可以高效运行，避免了CPU fallback的问题，基于稀疏门控专家混合模型，可通过门口网络实现只激活模型的部分结构，在增加模型容量和能力下不会成比例增加计算量；
        2.3 稀疏计算：支持常规的对权重进行稀疏化之外，还支持对激活值进行分块稀疏，进而降低计算量；
        2.4 动态混合精度：可以在运行时或AOT阶段设置每个算子的计算精度。  
Tenstorrent通过软硬协同设计方式，将数据并行和模型并行的部分功能实现下沉到硬件层，有效解决了横向扩展问题，这样就可以替代当前主流深度学习框架在分布式实现方面的大量编码工作，进而降低了深度学习框架的开发和使用门槛。同时，硬件的变化并没有降低软件栈的通用性，其软件栈支持PyTorch等主流框架。另一方面，芯片具有高度模块化，多个芯片可通过标准以太网端口连接在一起，进而扩展成大型AI网络。由于芯片内已集成NoC，因此这种扩展并不需要额外的交换机，因此扩展灵活度很高。  
- [MegEngine Inference 卷积优化之 Im2col 和 winograd 优化 | MegEngine Bot](https://zhuanlan.zhihu.com/p/532187602)  
摘要：卷积在推理时的优化有方式，本文主要介绍 Im2col+matmul 卷积以及 Winograd 卷积方式。  
im2col+matmul：和矩阵乘具有很多相似的特点，因此该方法使用 Im2col 的操作将卷积运算转化为矩阵运算，最后调用高性能的 Matmul 进行计算。该方法适应性强，支持各种卷积参数的优化，在通道数稍大的卷积中性能基本与 Matmul 持平，并可与其他优化方法形成互补。  
Winograd：按照 Winograd 算法的原理将卷积进行转变，达到减少卷积运算中乘法总量。其主要是通过将卷积中的乘法使用加法来替换，并把一部分替换出来的加法放到 weight 的提前处理中，从而达到加速卷积计算的目的。Winograd 算法的优化局限为在一些特定的常用卷积参数才支持。
        
    
