---
layout: default
---

# 嵌入式AI简报 (2022-06-30)：  


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


> 导读：【新闻】；【论文】；【开源】；【博文】。


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：



> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  



## 论文  

- [meituan/YOLOv6: YOLOv6——精度与速度远超 YOLOv5 和 YOLOX 的新框架 | 美团技术团队](https://mp.weixin.qq.com/s/RrQCP4pTSwpTmSgvly9evg)  
代码：https://github.com/meituan/YOLOv6  
摘要：本文介绍了美团视觉智能部在目标检测框架方面的优化及实践经验，针对 YOLO 系列框架，在训练策略、主干网络、多尺度特征融合、检测头等方面进行了思考和优化，设计了新的检测框架-YOLOv6，初衷来自于解决工业应用落地时所遇到的实际问题：
    1. 更高效的 Backbone 和 Neck ：受到硬件感知神经网络设计思想的启发，基于 RepVGG style 设计了可重参数化（其结构在训练时有多分支拓扑，实际部署时可融合为单个 3x3 卷积）、更高效的骨干网络 EfficientRep Backbone 和 Rep-PAN Neck；
    2. 优化设计了更简洁有效的 Efficient Decoupled Head，维持精度同时，降低了一般解耦头带来的额外延时开销；
    3. 训练策略：采用Anchor-free 无锚范式，同时辅以 SimOTA 标签分配策略以及 SIoU 边界框回归损失来进一步提高检测精度。
在工业界常用的尺寸模型中：YOLOv6-nano 在 COCO 上精度可达 35.0% AP，在 T4 上推理速度可达 1242 FPS；YOLOv6-s 在 COCO 上精度可达 43.1% AP，在 T4 上推理速度可达 520 FPS。在部署方面，YOLOv6 支持 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等不同平台的部署，极大地简化工程部署时的适配工作。  



## 开源项目



## 博文

- [Tenstorrent芯片架构浅谈 | Adlik 深度学习推理工具链](https://mp.weixin.qq.com/s/y-P1X-QeLjozC7jvEeAolA)  
摘要：近年市场上的AI芯片层出不穷，根源上还是算法与应用均处于高速迭代，计算硬件底座自然需要不断更新。其中芯片公司Tenstorrent的芯片架构别具一格，本文尝试一探究竟。  
Tenstorrent共设计出3款芯片，其中Jawbridge是一款小型测试芯片，Grayskull和Wormhole则是对外商用芯片，可覆盖训练和推理场景。Tenstorrent的芯片架构设计目标是解决模型在训练或推理时无法高效灵活扩展（scale out）的问题，提出2个核心技术点：
    1. 摒弃传统的核间共享式内存架构，采用Multicore Private Memory Model：芯片重点在硬件层面和软件层面分别加强了数据通信能力。在硬件层自研片上互联Network on Chip(NoC), NoC是2D双向环路结构；
    2. 动态执行：
        2.1 运行时数据压缩，以设计较小容量的private memory，在芯片内多核间及芯片间的数据通信量也随之降低，进而从整体上可以获得更高的性能功耗比。另外，Packet Manager还可以处理reshape/flatten等tensor形状变换操作，且该操作可以与Compute Engine并行执行，时间上可以overlap；
        2.2 条件执行：片上的逻辑控制单元和计算单元均可以高效运行，避免了CPU fallback的问题，基于稀疏门控专家混合模型，可通过门口网络实现只激活模型的部分结构，在增加模型容量和能力下不会成比例增加计算量；
        2.3 稀疏计算：支持常规的对权重进行稀疏化之外，还支持对激活值进行分块稀疏，进而降低计算量；
        2.4 动态混合精度：可以在运行时或AOT阶段设置每个算子的计算精度。  

Tenstorrent通过软硬协同设计方式，将数据并行和模型并行的部分功能实现下沉到硬件层，有效解决了横向扩展问题，这样就可以替代当前主流深度学习框架在分布式实现方面的大量编码工作，进而降低了深度学习框架的开发和使用门槛。同时，硬件的变化并没有降低软件栈的通用性，其软件栈支持PyTorch等主流框架。另一方面，芯片具有高度模块化，多个芯片可通过标准以太网端口连接在一起，进而扩展成大型AI网络。由于芯片内已集成NoC，因此这种扩展并不需要额外的交换机，因此扩展灵活度很高。       
        
    
