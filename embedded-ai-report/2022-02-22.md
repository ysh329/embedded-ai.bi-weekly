---
layout: default
---

# 嵌入式AI简报 (2022-02-22)：


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  


> 导读：


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 英特尔：2月17日，CEO基尔辛格表示：“我们不是ARM的大客户，但我们确实在使用ARM的技术。随着我们也将ARM纳入我们的IFS(代工业务)议程，我们将成为ARM的更大客户。如果有财团来收购ARM，我们可能非常愿意以某种方式参与进来”；
- 智能手机：Counterpoint Research 2021Q4市场监测报显示，2021Q4中国智能手机出货量同比下降 11% 。苹果高居首位，达到历史最高市场份额，OPPO加上子品牌 OnePlus 升至第三。vivo作为第四，以16.5%的市场份额位列第四。小米跌至第五位，延续跌势；




> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  



## 论文  





## 开源项目

- [arogozhnikov/einops:斯拉AI高管都推荐的张量工具，开源了三年后终于中顶会ICLR 2022 Oral | 量子位](https://mp.weixin.qq.com/s/QxowSMirwnsUjIA-MFCj7g)  
代码：https://github.com/arogozhnikov/einops  
摘要：Flexible and powerful tensor operations for readable and reliable code. Supports numpy, pytorch, tensorflow, jax, and others.  
该框架基于爱因斯坦求和约定（Einstein summation convention）的思路开发，能够大幅提高代码的可读性和易修改性。同时，Einops支持Pytorch、TensorFlow、Chainer、Jax、Gluon等多个深度学习框架，以及Numpy、Cupy等张量计算框架。ICLR 2022将其接收为Oral论文。  
Einops的基本原理来自于爱因斯坦在1916年提出的爱因斯坦求和约定，也叫爱因斯坦标记法（Einstein notation）：当一组乘积中，有两个变量的脚标一样，就要对相同的两个脚标求和，可避免公式里出现大量的求和符号，看起来更简洁如Numpy种就有使用。  
但Einops正是基于Einsum进行了诸多改进，针对张量操作过程中一些以前难以解决的问题，提供了更加便利的方案。那不得不说Einops的本质：通过针对变换模式的新的标记法，能够确保元素在张量中的位置与坐标变量的值一对一映射。如`nn.transpose(x, [0,3,1,2])`可以写成`rearrange(x, 'b h w c -> b c h w')`。与爱因斯坦求和约定（Einsum）相比，Einops有3个规则，让Einops的代码可读性很高：
    1. axis present only in the input (the left hand side) is reduced (e.g. with max-reduction)
    2. axis present only in the output is “repeated” (tensor values are the same for all index values of
new axes)
    3. all axis identifiers on either side of expression should be unique (numpy.einsum allows repeats to
cover traces).
综上，einops可灵活地处理高维度数据。

## 博文



- [MegEngine 的 CUDA 矩阵乘法终极优化 | 旷视研究院](https://mp.weixin.qq.com/s/XX5q36gwfqKyPaQOkiUx8w)  
摘要：单精度矩阵乘法（SGEMM）几乎是每一位学习 CUDA 的同学绕不开的案例，这个经典的计算密集型案例可以很好地展示 GPU 编程中常用的优化技巧，而能否写出高效率的 SGEMM Kernel ，也是反应每一位 CUDA 程序员对 GPU 体系结构的理解程度的优秀考题。本文将详细介绍 CUDA SGEMM 的优化手段，适合认真阅读过《CUDA C++Programming Guide》，具备一定 CUDA 编程基础的同学阅读，希望能给追求极致性能的同学们一些启发。  
- [快手特效业务的云端渲染方案 | 快手Y-tech团队](https://mp.weixin.qq.com/s/MG3NUy4R4pDbsZhp0i6BsA)  
摘要：云渲染就是依托于云计算的一种云端渲染服务。用户将本地的渲染任务提交到远程服务器，通过远程的计算机集群资源进行运算操作，将上传的任务进行云端处理后再返回给本地，由用户下载提取。使用云端渲染可以更好的支持业务需求，如随时支持特效相关的H5活动，以及充分利用服务端的大内存和高性能，结合Y-tech的AI能力，给用户提供更完美好看、好玩的画面效果。  
主要的难点之一便是云端渲染的耗时优化，随着输入视频时长的增加以及业务场景复杂度的提升，耗时的增加导致用户的等待时长以及服务器资源的成本都在不断提高，所以云端渲染急需在性能耗时等方面做各种优化处理。  
通过充分利用服务器的多核优势：将解码、渲染、编码三个模块解耦拆分、进行多线程异步处理。针对一些长视频处理过程中的瓶颈，进一步将编码、解码模块内部重构，支持多线程解码、多线程编码，在性能上满足更复杂的需求。使用一分钟的输入视频进行测试，特效及输出不变的情况下，针对多线程方面的优化耗时提升明显，优化后CPU和GPU利用率是之前的三倍，耗时较之前可提高2.5倍左右。  









