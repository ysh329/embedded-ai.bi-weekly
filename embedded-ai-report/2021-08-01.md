---
layout: default
---

# 嵌入式AI简报 (2021-08-01)：


**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：


好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 高通：正研发一款 SM8450 的芯片代号为 Waipio ，将是骁龙888真正的迭代更新即骁龙895或898，将采用三星4nm工艺，CPU 由 X2@3.09GHz + 3xA710 + 2xA510@high + 2xA510@low 组成；
- 联发科：**新款移动计算平台迅鲲（Kompanio） 1300T**。采用台积电 6nm ，**4xaA78 + 4x@A55 + Mali-G77 MC9**，搭载 HyperEngine 3.0 游戏引擎。还集成**APU 3.0 AI单元**，提供支持智能语音(语音助手/超低功耗语音唤醒/多款音效框架)、视觉应用。首款搭载迅鲲 1300T 的平板电脑可能是 8 月 12 日将发布的荣耀平板 V7 Pro；
- 龙芯中科：首款自主架构 LoongArch 的处理器 3A5000 正式发布，LoongArch 从顶层架构，到指令功能和ABI标准等全自主，满足兼容生态、跨指令平台应用的需求，处理器主频2.3GHz-2.5GHz，4核心，每核心为 64 位超标量 GS464V 自主微结构，包含4个定点单元、2个256位向量运算单元和2个访存单元；国内第三方测试其在GCC编译环境下运行SPEC CPU2006的定点、浮点单核Base分值均达到26分以上，四核分值达到80分以上；
- GlobalFoundries：CEO Tom Caulfield表示，该公司坚持明年IPO计划，有关成为英特尔公司收购目标的报道只是猜测。格芯是阿布扎比财团投资部门的一家芯片制造商；
– Imagination：**宣布任命白农（Wallace Pai）担任中国区董事长**，深化中国市场战略，在战略、销售与业务合作方面有丰富经验，后者曾在中芯国际/格芯担任副总或高管，在三星/谷歌/高通/Cadence/Intel担管理等；
- 台积电：**Q2财报发布后，股价大跌5.5%，市值蒸发2300亿**。原因是失去华为麒麟芯片的代工订单导致利润下滑。同时因为失去华为抢占产能，苹果可以选择三星和台积电，打压台积电订单价格，导致台积电利润进一步下滑。今年 2 月董事会通过将斥资 28 亿美元扩建月产4万片的28纳米产能的南京厂，但美方施压下，预计明年下半年开始量产；
- Canalys：发布全球Q2智能手机市场份额的报告，小米市场份额17%，智能手机销量超越了苹果，晋升全球第二；
- Intel：在欧盟多国游说，拟投资 200 亿美元建芯片工厂，希望获得财政和政治支持。预计将在今年年底完成 8 个选址工作；宣布其旗下的工厂将开始制造高通芯片，并公布了公司有史以来最详细的制程工艺和封装技术路线图，希望在 2025 年前赶上台积电、三星电子，**将为 AWS、高通代工芯片，AWS 将成为首个使用英特尔代工服务（IFS）封装解决方案的客户，高通也将采用 Intel 20A 制程工艺技术**。英特尔还将采用下一代高数值孔径（High-NA）EUV 技术；
- Cadence Design：CEO Lip-Bu Tan 将于 2021 年 12 月 15 日转任执行董事长，届时 Anirudh Devgan 将接任Cadence首席执行官职位。Devgan 一直负责监督所有研发、销售和现场工程以及企业战略、营销和业务发展团队，当中还包括并购，并推动了技术和产品路线图，是公司当前行业领先解决方案背后多项突破性创新的架构师；
- AMD：2021Q2财报营业额同比增长99% 毛利润增至48%，营业额为38.5亿美元，经营收入为8.31亿美元，净收入为7.1亿美元，摊薄后每股收益为0.58美元。非GAAP经营收入为9.24亿美元，净收入为7.78亿美元，摊薄后每股收益为0.63美元。主要得益于计算与图形事业部及企业、嵌入式和半定制事业部的较高营业额；
- Nvidia：收购 Arm 再延迟。但 Arm CEO Simon Segars 说：“Arm 没有进行 IPO 计划，我们 100% 专注于完成这笔交易”，此前他曾公开反对上市，认为 Arm 需要更多投资来扩展到数据中心和人工智能领域，而这作为上市公司是不可能的。本月初，Segars 先生写道：“Arm 和 Nvidia 的合并比 IPO 更好。引领人工智能所需的投资水平将是前所未有的”；
- Arm China: 与清华集成电路学院、中兴微电子、TCL集团工研院、全志科技、瑞芯微电子、长安汽车研究院、前海七剑等多家企业和机构共同发起的智能计算产业技术创新联合体（Open NPU Innovation Alliance，简称ONIA）成立“智能计算产业技术创新联合体”，并**正式宣布全球首个开源神经网络处理器指令集架构（NPU ISA）**。今后将以标准协作等方式制定、批准和维护开源NPU ISA，并为未来的规范设定方向，构建由中国本土发起、以全球领先技术为标准的智能计算产业生态，实现NPU处理器创新和智能计算的持续演进；
- 腾讯: **在招聘官网出现多个芯片研发岗位信息**，包括芯片架构师、芯片验证工程师、芯片设计工程师等，工作地点可选北京、上海、深圳等。腾讯相关人士回应称，**在特定的领域如 AI 加速和视频编解码有在做技术尝试**，非通用芯片；
- 云从：将在 7 月 20 日迎来 IPO 大考。7月15日对外披露了第三轮问询回复答卷，与此同时，公司被迅速安排上会，将在 7 月 20 日迎来 IPO 大考，云从科技若能成功过会、注册，公司将毫无悬念摘得“AI 四小龙”第一股的桂冠；
- 酷芯：首发全新一代 AR93XX 系列高性能 AI SoC，**集成自研 900 万像素 ISP 和 4T 算力 NPU 等 IP**，并展出与合作伙伴开发智慧解决方案。结合 4K@60fps 编解码，单核 CEVA XM6 高性能 DSP，4 核 ARM Cortex-A53，自研 SoC 架构，综合处理能力**宣称业界最优**；
- 芯驰：宣布完成近 10 亿元 B 轮融资。本轮融资由普罗资本旗下国开装备基金与云晖资本联合领投，董事长张强表示融资将用于更先进制程芯片的研发，实现更好的性能和功耗表现，推动智能驾驶更快落地。


> 注：个别链接打不开，请点击文末【阅读原文】跳转。


## 业界新闻  

- [https://www.nature.com/articles/s41586-021-03625-w
摘要：PlasticARM 是使用工业标准芯片实现工具，采用 PragmatIC 的 0.8 μm 工艺实现的。下图 1c 展示了 FlexIC 的布局，从中可以看出 Cortex-M 处理器、RAM 和 ROM 的分布。PlasticARM 是使用一条名为「FlexLogIC」的商业「fab-in-a-box」生产线制造的，其 die 显微图像如下图 1d 所示。
Arm 等机构的研究人员在最近的一项研究中表示，他们尝试将芯片电路和组件打印在塑料基板上，就像打印机在纸上打印墨水一样。

Arm 柔性芯片的微处理器是采用柔性电子制造技术制造的，该技术也被称为「天生灵活的处理引擎（natively flexible processing engine）」。他们使用的技术包含金属氧化物 TFT。金属氧化物 TFT 成本很低，而且可以缩小，方便大规模集成。

早期的原生柔性处理器相关工作是基于使用低温多晶硅 TFT 技术开发 8 位处理器，这种技术制造成本高，横向可扩展性差。最近，基于二维材料的晶体管被用于开发处理器，例如使用二硫化钼（MoS2）晶体管的 1 位 CPU 以及由碳纳米管场效应晶体管构造的 16 位 RISC-V CPU。然而，这两项工作都是在传统的硅片上进行的，而不是在柔性基板上。
Arm 柔性芯片的微处理器是采用柔性电子制造技术制造的，该技术也被称为「天生灵活的处理引擎（natively flexible processing engine）」。他们使用的技术包含金属氧化物 TFT。金属氧化物 TFT 成本很低，而且可以缩小，方便大规模集成。

早期的原生柔性处理器相关工作是基于使用低温多晶硅 TFT 技术开发 8 位处理器，这种技术制造成本高，横向可扩展性差。最近，基于二维材料的晶体管被用于开发处理器，例如使用二硫化钼（MoS2）晶体管的 1 位 CPU 以及由碳纳米管场效应晶体管构造的 16 位 RISC-V CPU。然而，这两项工作都是在传统的硅片上进行的，而不是在柔性基板上。
- [谷歌进一步推广 TensorFlow Lite 到 Android APP 开发者]()  
摘要：谷歌近期决定将 Android ML 平台 —— 主要是 TensorFlow Lite 直接添加到 Play services 中，帮助提高机器学习技术在 Android 系统中的使用率。Google Play services 是负责 Android 上面向用户的关键功能，并为第三方应用程序开发人员提供了各种工具的访问，最新添加的功能将会是设备上的机器学习。  
- [双核+ GPU 加持，华米科技黄山 2S 来了：智能可穿戴芯片进入全新时代 | 机器之心](https://mp.weixin.qq.com/s/KlPwyE32oZLkRvePwhF4xQ)  
摘要华米在合肥举行的发布会上，推出了新一代双核 RISC-V 架构可穿戴芯片黄山 2S、自研可穿戴操作系统 Zepp OS、血压测量引擎 Pump Beats 等多项新技术。该芯片中还集成了一颗 2.5D GPU，图形加速性能比上一代提升 67%，可独立处理图形相关指令，让操作系统运行更加流畅。在实机演示中，它可以让手表上的 UI 界面最高达到 60Hz 刷新率。此外，黄山 2S 芯片搭载的卷积神经网络加速处理单元，可以迅速识别疾病类型；在处理房颤识别任务时，识别速度是纯软件计算的 26 倍。  
- [解密谷歌自研手机芯片，三星 5nm + Arm 超大核，能扛五代安卓更新 | 芯东西](https://mp.weixin.qq.com/s/q-Z2667Ud6CANiwW0vC7Vw)  
摘要：近日，外媒曝光谷歌自研手机芯片Whitechapel的更多参数细节。该芯片据传由谷歌和三星合作研发，采用三星5nm工艺，其CPU将用上两个Cortex-A78内核，并会搭载Mali-G78 GPU和Dauntless安全芯片。谷歌即将发布的Pixel 6和Pixel 6 Pro新款手机预计将率先搭载这款自研芯片。  
该芯片预计将采用三簇CPU设计，包含两个Arm官方超大核Cortex-A78内核、两个Cortex-A76内核和三个Cortex-A55内核。这款SoC还拥有与三星Galaxy S21手机Exynos处理器相同版本的GPU，即Arm Mali-G78 GPU。
谷歌原有目标是为其智能手机系列带来旗舰级的性能。但据相关媒体报道，早期Whitechapel芯片的产品验证测试（Product Validation Test，PVT）阶段性能评估结果表明，相对于骁龙888，Whitechapel芯片性能更接近于骁龙870。  
有外媒猜测，谷歌可能更倾向于提升芯片的人工智能和机器学习性能，而不是像苹果公司的A系列芯片那样去制造性能最快的芯片。  




## 论文


- [MobiSys 2021] [可高效、准确地预测模型推理时间的系统nn-Meter | 微软研究院AI头条](https://mp.weixin.qq.com/s/_axPjHPLCh1rgTqfCbDBUg)  
摘要：微软亚洲研究院的论文“nn-Meter: Towards Accurate Latency Prediction of Deep-Learning Model Inference on Diverse Edge Devices”获得了 MobiSys 2021 的最佳论文奖（Best Paper），并且成为本届大会中唯一个获得了 Artifact Evaluation 全部三个最高级别徽章的工作。  
深度神经网络（DNN）模型在实际部署中的延迟（推理时间）是决定模型是否可用的一个重要指标。然而，模型设计过程中对数以亿计的设计选项进行实际的部署和延迟评估会造成巨大的开销。因此，如何进行高效、准确的模型运行延迟预测对模型的设计至关重要。但现有技术缺乏对部署平台优化策略的理解以及对灵活多变模型架构的泛化性，所以无法做到准确的模型推理时间预测。  
针对上述问题，微软亚洲研究院异构计算组的研究员们提出并开发了nn-Meter 模型推理时间预测系统。该系统可高效、准确地预测 DNN 模型在不同边缘设备上的推理延迟，其关键思想是将整个模型划分为内核（kernel），即设备上的执行单元，然后执行内核级预测。  
与基准方法相比，nn-Meter 是唯一能够在各种设备上始终实现准确预测的方法。平均而言，nn-Meter 89.2% 的准确率明显优于 FLOPs (22.1%)、FLOPs+MAC(17.1%) 和 BRP-NAS (8.5%)。nn-Meter 在完整的包含26,000个模型的基准数据集上（表2） 的预测结果中，分别在移动 CPU 和 GPU 上实现了99.0%和99.1%的预测准确率。在 Intel VPU 上，nn-Meter 则可以在±10%的误差范围内达到83.4%的预测准确率。  
nn-Meter 建立在两个关键技术之上，从而可以准确预测不同模型在部署中的推理时间，以设计真正高效的模型：
    - 内核检测：能够自动识别部署平台的优化策略，从而基于这些策略将模型分解为实际运行的内核，nn-Meter 会离线收集所有融合规则，对于在线模型预测，内核搜索算法则会将这些规则递归地应用于目标模型来找到所有内核。  
    - 自适应数据采样：从整个设计空间中有效地采样最有益的配置，以高效地构建准确的内核级延迟预测器。  
对于每个内核，nn-Meter 都会提取特征并预测其延迟，所有内核预测延迟之和则为整个模型的预测延迟。
- [2107.12292] [JDAI-CV/CoTNet：京东AI开源最强 ResNet 变体 CoTNet，即插即用的视觉识别模块 | 极市平台](https://mp.weixin.qq.com/s/AUBtxtriRMi2lud8E7w5cA)  
摘要：本文是京东AI研究院梅涛团队在自注意力机制方面的探索，不同于现有注意力机制仅采用局部或者全局方式进行上下文信息获取，他们创造性的将Transformer中的自注意力机制的动态上下文信息聚合与卷积的静态上下文信息聚合进行了集成，提出了一种新颖的Transformer风格的“即插即用”CoT模块，它可以直接替换现有ResNet架构Bottleneck中的卷积并取得显著的性能提升。无论是ImageNet分类，还是COCO检测与分割，所提CoTNet架构均取得了显著性能提升且参数量与FLOPs保持同水平。比如，相比EfficientNet-B6的84.3%，所提SE-CoTNetD-152取得了84.6%同时具有快2.75倍的推理速度。  
    1. 技术上来讲，CoT 模块首先通过卷积对输入keys进行上下文信息编码得到关于输入的静态上下文表达；进一步将编码keys与输入query进行拼接并通过两个连续卷积学习动态多头注意力矩阵；所得注意力矩阵与输入values相乘即可得到关于输入的动态上下文表达。

2.CoTNet-50直接采用CoT替换Bottlenck中的卷积；类似的，CoTNeXt-50采用CoT模块替换对应的组卷积，为获得相似计算量，对通道数、分组数进行了调整：CoTNeXt-50的参数量是ResNeXt-50的1.2倍，FLOPs则是1.01倍。


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。


- [mindspore-ai/mindspore: 发布1.3版本，打造无所不在的智能，诠释可以信赖的开源 | MindSpore](https://mp.weixin.qq.com/s/9N_Ib8ZbgbVVEn-7R8zpKg)  
摘要：在这个版本中为大家带来了全新的MindSpore Federated能力，解锁了支撑盘古千亿稠密大模型的众多关键特性、以及面向更多类型硬件的推理优化、图算融合、简易部署等。  
- [taichi-dev/quantaichi：99行代码实现冰雪奇缘特效的「太极」再进化，胡渊鸣团队、快手等联合打造 | 机器之心](https://mp.weixin.qq.com/s/vJFOziFu2Dre6QQbXeAtRA)  
论文：https://yuanming.taichi.graphics/publication/2021-quantaichi/quantaichi.pdf  
项目：https://yuanming.taichi.graphics/publication/2021-quantaichi/  
代码：https://github.com/taichi-dev/quantaichi  
摘要：现代动画电影（包括《冰雪奇缘》等），经常使用基于物理的动画生产特效，丰富感官的体验。基于粒子的表示是其中常用的方法。场景越大，粒子就越多。比如，要模拟一个 300 米长的溃坝场景中的水，可能会需要数千万粒子，而这些粒子的存储需要大量显存。比如说，如果需要96GB的显存，则需要购置大量高端显卡，如 4 块 NVIDIA Quadro P6000 GPU。  
针对这一现状，快手、麻省理工、浙大、清华的研究者进行了物理编译器自动量化方面的研究，提出了一套用于量化模拟的新的语言抽象和编译系统——QuanTaichi。它可以使用低精度量化的数字数据类型并将其打包（packing）以表示模拟状态，从而减少了内存空间和带宽消耗。有了这项技术的加持，高精度的物理模拟只需要一块 GPU 就能实现。  
QuanTaichi 的实现基于 MIT CSAIL 胡渊鸣等人之前提出的「太极（Taichi）」编程语言和编译器。太极技术已经让快手成为首个推出实时液体及烟雾模拟动态效果的短视频和直播平台，行业首发了「别哭鸭」、「我要去潜水」、「火焰超能力」等特效。其中，「圣诞快乐」魔法表情成为爆款，有 74 万用户拍摄并上传了视频，大约有两千多万用户观看了太极支持的这款魔法表情。  
- [KaiyuYue/torchshard：训练大模型也不怕，轻量级TorchShard库减少GPU内存消耗，API与PyTorch相同 | 机器之心](https://mp.weixin.qq.com/s/IPO_FhFFtg7ajaVyEVrA0w)  
摘要：训练大模型时，如何优雅地减少 GPU 内存消耗？你不妨试试这个 TorchShard 库，兼具模型并行与数据并行等特点，还具有与 PyTorch 相同的 API 设计。马里兰大学帕克分校计算机科学系的研究者 Kaiyu Yue 开源了一个工具TorchShard，这是一个轻量级的引擎，用于将 PyTorch 张量切片成并行的 shard。当模型拥有大量的线性层（例如 BERT、GPT）或者很多类（数百万）时，TorchShard 可以减少 GPU 内存并扩展训练规模，它具有与 PyTorch 相同的 API 设计。  
TorchShard 是对模型并行单元（mpu）的彻底重写，是 Megatron-LM 核心。最重要的是，TorchShard 具有与 PyTorch 相同的 API 设计，这意味着所有的子类和子函数都保持与 PyTorch 相同。除此之外，TorchShard 还支持与 DDP 一起使用时的各种特性，保存和加载 shard checkpoints，初始化 shard 参数，以及跨多台机器和 GPU 处理张量。  
- [tensorflow/tfjs-models：实时检测17个人体关键点，谷歌SOTA姿态检测模型，手机端也能运行 | 机器之心](https://mp.weixin.qq.com/s/2Mk_FQoTB1wLmkyk5X865w)  
代码：https://github.com/tensorflow/tfjs-models/tree/master/pose-detection  
摘要：近日，来自谷歌的研究者更新了用于实时姿态检测的项目，该项目包含 3 种 SOTA 模型，其中 MoveNet 模型可检测人体 17 个关键点、并以 50+ fps 在电脑和手机端运行；BlazePose 可检测人体 33 个关键点；PoseNet 可以检测人体多个姿态，每个姿态包含 17 个关键点。
- [kingsoft-wps/KSAI-Toolkits：AI加持的WPS来了：金山开源全球首个办公DL框架KSAI-Lite | 机器之心](https://mp.weixin.qq.com/s/yxbRZH3Wlql09ZQStelHpw)  
代码：https://github.com/kingsoft-wps/KSAI-Toolkits  
摘要：金山办公还发布了一款人工智能深度学习推理框架 KSAI-lite，这是一款免费、开源、跨多个终端的全新工具，适配国内外主流软硬件平台，在 OCR、机器翻译、智能校对等落地场景上为开发者们带来了新选择。KSAI-lite 面向通用性、高性能、轻量和专业性四个目标构建。  
在技术实践中，金山的开发团队在多框架支持、软硬件适配、性能、功耗、内存等方面都进行了优化。在 KSAI-lite 中首个开源的是 OCR 模型，其支持移动端设备的离线识别，模型和库文件共计不到 9MB。该模型在文本检测、文本分类和文本识别上都表现出了业内第一梯队的性能。据介绍，KSAI-lite 框架底层基于 TensorFlow。  

## 博文

