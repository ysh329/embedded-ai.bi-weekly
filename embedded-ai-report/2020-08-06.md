---
layout: default
---

# 嵌入式AI简报 (2020-08-06)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次

先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- ARM中国，对「换帅门」事件再次发布了公开信，立场坚定不变；
- ARM，ARM出售，英伟达接盘难，台积电感兴趣；
- 英特尔，硬件高管和首席工程师离职；7nm CPU发布推迟6个月；更新[Intel® Architecture Instruction Set Extensions Programming Reference](https://software.intel.com/content/www/us/en/develop/download/intel-architecture-instruction-set-extensions-programming-reference.html)，AMX矩阵计算ISA马上就来了；
- 高通，原本交给三星5nm制程的骁龙875出问题，现在5G旗舰芯片交由台积电代工；
- 苹果，iPhone 12系列将采用A14处理器，台积电5nm制程。A14可能会内置125亿个晶体管，性能更强、功耗更低，大概率60Hz刷新率屏幕；
- 联发科，预计2021Q2推出5G旗舰手机SoC天玑2000，基于5nm；
- 华为，按照惯例新一代芯片9月发布，台积电5nm工艺，有望命名为麒麟1020，随Mate新旗舰首发；
- 小米，mi10超大杯rom内置Game Turbo界面，传闻与高通开发，支持Adreno GPU的频率、自定义设置等；
- 2020Q2全球智能手机市场报告，7月30日由第三方调研机构Canalys发布：华为智能手机出货5580万台，首次超越了三星，成为冠军。

> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻


- [2020苹果Core ML框架三大更新：更多层类型、模型加密、基于CloudKit模型部署 | 新智元](https://mp.weixin.qq.com/s/XrJxXH8ObRF1QWU1IZGwPQ)  
摘要：今年苹果WWDC全球开发者大会上，Core ML框架有三项更新：更多的层Op类型支持如针对InnerProductLayer、BatchedMatMulLayer的8位量化Op。CPU上的Core ML现在也可以使用16位浮点运算而不是32 位浮点运算（在A11 Bionic及更高版本上）。16位浮点数现在是一流的Swift数据类型。在CPU方面，也支持16位浮点数，速度可提高两倍以上！也支持了在CloudKit上托管模型更新能力，方便用户做模型集合的版本管理。还有对模型加密的支持，自动加密和解密模型，防止用户窥探mlmodelc文件夹。  
- [MediaTek发布最新5G芯片天玑720，为中端智能手机打造非凡5G体验 | 联发科技](https://mp.weixin.qq.com/s/EGbvNpvLompFyqjKwAz2fQ)  
摘要：MediaTek推出最新5G SoC——天玑720，进一步推动5G中端智能手机的普及。天玑720采用7nm制程，集成低功耗5G调制解调器，支持90Hz屏幕刷新率。  
天玑720采用八核CPU，包含两个主频为2GHz的ArmCortex-A76大核，提高了应用的响应速度和流畅的使用体验。天玑720还搭载了Arm Mali-G57 GPU、集成的MediaTek APU（AI处理器）还提供了一系列AI相机增强功能、LPDDR4X内存和UFS 2.2闪存可实现更快的读写速度。  
- [Exynos 1000曝光：AMD GPU降临手机 | 安兔兔](https://mp.weixin.qq.com/s/K_Uaxiv1BmZfy7AaFRV6Ww)  
摘要：Exynos 1000最快2021年上市，极可能首搭AMD GPU，图形性能大幅提升。Exynos 1000由三星Galaxy S21 Ultra（暂命名）首发，至于S21+和S21则碍于成本原因换装其它SoC。与此同时，Exynos 1000还将采用5nm工艺打造，和高通骁龙875同期量产，颇有对标意味。据悉，Exynos 1000的GPU是三星和AMD Radeon合力开发，图形性能预计会有大幅度的提升，表现非常值得期待，毕竟高通骁龙的Adreno GPU之所以那么强，少不了当年AMD的助力。  
至于CPU方面，考虑到奥斯汀部门已经解散，所以Exynos未来会重新使用公版架构，比如ARM前不久发布的Cortex A78和Cortex X1，皆可能出现在Exynos 1000之中。除了Exynos，传闻高通最新SoC骁龙875也会采用魔改后的Cortex A78和Cortex X1，实现超大核架构。  
- [国产顶级旗舰获Adreno GPU驱动升级：性能白给 | 安兔兔](https://mp.weixin.qq.com/s/HXuyu1-FEBYaCqY-Ixy0Nw)  
摘要：在去年骁龙技术峰会上，高通在Elite Gaming体验中推出了GPU驱动更新计划，搭载骁龙865/765系列的机型可获得后续的驱动升级。目前，国内机型小米10/Pro、Redmi K30 Pro均支持在应用商店升级GPU驱动更新，可增强游戏性能和稳定性，同时给Vulkan性能优化。  
部分手持OPPO Find X2 Pro的用户开始收到了GPU驱动升级推送，同样是在应用商店更新，下载OplusGpudriver即可实现升级，驱动版本为0474.0，具体功能两方面：增游戏应用的运行稳定性、Vulkan性能优化。  
需驱动升级需要更新到最新系统版本，升级成功后GPU驱动版本会从444变成474，可在设置-游戏驱动程序偏好设置中选择最新驱动，理论上跑分会有所提升。  
- [谷歌第四代TPU性能首曝光，NVIDIA A100破8项AI性能记录 | 芯东西](https://mp.weixin.qq.com/s/yA8FMNmPSADqTviTZ8m7Xg)  
摘要：在最新机器学习性能的行业标准MLPerf基准测试中，NVIDIA和谷歌接连公布打破AI性能记录的消息，NVIDIA和谷歌分别也是通用和专用AI芯片的代表玩家。  
NVIDIA宣布其A100 Tensor Core GPU在加速器的全部8项MLPerf基准测试中展现了最快的市售商用产品性能，谷歌称其机器学习训练超级计算机在8项MLPerf基准测试连创6个性能记录。谷歌第四代TPU芯片性能也首次披露，得益于硬件创新及软件优化，TPU v4的性能较TPU v3平均提升2.7倍，此外基于TPU v3的谷歌最强ML训练超算峰值性能超430 PFLOPs。详见：https://www.mlperf.org/training-results-0-7  
- [TensorFlow惊现大bug，用户转Pytorch | 机器之心](https://mp.weixin.qq.com/s/vqZMDlDEEvj181zq4JrqJw)  
摘要：Keras 基于 TF 的 API 出现bug， 用户创建的自定义层的梯度有无法更新等问题，且找不到 trainable_variables 和 non_trainable_variables。  


## 论文


- [2007.10319] [韩松团队新作 | MCUNet | IoT设备+微型机器学习时代已经到来了](https://mp.weixin.qq.com/s/g-atrsTylCB3rmMHEvdFkQ)  
标题：MCUNet: Tiny Deep Learning on IoT Devices  
地址：https://arxiv.org/abs/2007.10319  
摘要：MIT韩松团队提出了一种适用于IoT设备的模型设计方案，它将NAS与Engine进行了协同设计，从而确保了模型可以更好的在微型处理器上运行，同时具有更高的精度。  
- [2003.08646v3] [LANCE: Efficient Low-Precision Quantized Winograd Convolution for Neural Networks Based on Graphics Processing Units](https://arxiv.org/abs/2003.08646v3)  
链接：https://arxiv.org/abs/2003.08646v3  
摘要：本文结合快速卷积和量化技术的优点，提出了一种高效的低精度量化Winograd卷积算法LANCE。通过在Winograd域中嵌入线性量化运算，可在GPU的低精度计算下高效地进行快速卷积。LANCE的评测基于常见图像分类数据集（包括SVHN、CIFAR和ImageNet），作者提出的8位量化Winograd卷积性能比全精度卷积提高了2.40倍，精度损失很小。  
- [2007.14178v1] [Optimization of XNOR Convolution for Binary Convolutional Neural Networks on GPU](https://arxiv.org/abs/2007.14178v1)  
链接：https://arxiv.org/abs/2007.14178v1  
摘要：BNN模型的计算负载和内存占用都有较大优势，但实际性能在具体硬件的加速上一直表现不好，本文作者提出了一个在GPU上实现二元卷积网络推理的方法，重点是xnor卷积的优化。实验结果表明，在conv3x3的情况下，使用NVIDIA GPU可以有42.61倍的加速。  
代码：https://github.com/metcan/Binary-Convolutional-Neural-Network-Inference-on-GPU  


## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [Oneflow-Inc/oneflow: OneFlow开源，TensorFlow和PyTorch迎来了“后浪” | InfoQ](https://mp.weixin.qq.com/s/m0pV4yaZFI3bTg_-mUcaoQ)  
链接：https://github.com/oneflow-inc/oneflow  
OneFlow技术开发文档：https://github.com/Oneflow-Inc/oneflow-documentation/blob/master/en/docs/basics_topics/essentials_of_oneflow.md  
摘要：oneflow的主要特点之一，是对分布式大模型训练场景的支持。可以让编译器自动编排并行模式和流水线，编译器自动解决从逻辑任务到硬件资源的映射，包括数据并行、模型并行、流水并行的设备分配以及数据路由方案，大大降低分布式编程的复杂度，用户只需要关心任务的逻辑结构以及本次任务可使用的硬件资源，而不用去编程实现数据在硬件资源中的流动机制。
此外，静态调度、去中心化协议、流式执行引擎，都是其主打的特色。在易用性和完备性上，OneFlow这个后浪还有发展空间，但在高性能方面，首屈一指。  
- [MindSpore新版本v0.6.0-beta解读 | MindSpore](https://mp.weixin.qq.com/s/96qfwRBs1C0ynwYOT5-Kpg)  
摘要：MindSpore0.6.0版本发布，其中包括Serving模块，是一个轻量级、高性能的服务模块，为生产环境而设计，旨在帮助开发者在生产环境中高效部署在线推理服务；参数服务器分布式训练，支持同步SGD和异步SGD。扩展性上，将模型的计算与模型的更新分别部署在Worker和Server两类进程中，使得Worker和Server的资源可以独立地横向扩缩；支持超大规模稀疏特征训练，像特征数量可能是千万到百亿的规模，Embedding参数量是GB级到TB级。MindSpore在全下沉模式（所有计算都在Device上）之外，提供了Host-Device混合执行模式，即Embedding部署在host测，DNN和通信下沉到Device侧，来解决embedding容量的问题，发挥昇腾芯片算力；并在此基础上实现了混合并行（Embedding模型并行，DNN数据并行）实现超大规模Embedding的高性能训练。  
更多v0.6版特性见：https://gitee.com/mindspore/mindspore/blob/r0.6/RELEASE.md  
- [pytorch/pytorch：PyTorch 1.6来了新增自动混合精度训练、Windows版开发维护权移交微软 | 机器之心](https://mp.weixin.qq.com/s/Uc2deh0-Ex6_FRh2vYuJGg)  
摘要：PyTorch 1.6 正式发布！新版本增加了一个 amp 子模块，支持本地自动混合精度训练。Facebook 还表示，微软已扩大了对 PyTorch 社区的参与，现在拥有 PyTorch 在 Windows 上的开发和维护所有权。  
- [jiangzhongbo/TengineKit_Demo_Big_Eyes：开源212点人脸关键点SDK实现抖音大眼特效](https://github.com/jiangzhongbo/TengineKit_Demo_Big_Eyes)  
摘要：抖音短视频中的大眼特效有很多人玩，这篇就讲一下怎么实现。本文为《抖音美颜效果开源实现，从AI到美颜全流程讲解》姐妹篇，很多代码和内容都类似，看过的同学可以直接看源码。大眼特效原理与美颜差不多，是AI和计算机图形学的结合。美颜是的基本原理就是深度学习加计算机图形学。深度学习用来人脸检测和人脸关键点检测。计算机图形学用来磨皮，瘦脸和画妆容。  
- [chengzhengxin/deep-sdm：开源250FPS的人脸106特征点，3.3M模型 | 知乎](https://zhuanlan.zhihu.com/p/165932077) 
摘要：开源的算法是deep-sdm（有监督梯度下降法），也就是sdm的deep版本，是将经典算法sdm中的HOG特征提取器，以及线性回归器，利用CNN替换后得到的人脸特征点定位算法。在MacBook 16-inch CPU上实测能够达到250FPS，利用ncnn移植到移动端能够保持100FPS以上。模型文件若以fp16存储，模型大小可降低到1.6M。  

## 博文

- [OneFlow 线上交流会I Eager 项目讨论（内附完整视频） |  OneFlow之窗](https://mp.weixin.qq.com/s/3Nhqoejk1UqCW1871if42A)  
摘要：2020年8月3日晚，OneFlow 在线上进行了第一次有社区朋友参加 OneFlow 的分布式并行易用性以及进行中的 Eager 项目讨论，内容主要包括三个部分：OneFlow 的分布式并行易用性；Eager 的设计；Eager 的性能优化。  
全程约3小时，OneFlow 的同事与社区的朋友一起提问、探讨、头脑风暴，完成了 OneFlow 开源后的第一次 Meetup。 
- [AI编译优化——总纲](https://mp.weixin.qq.com/s/tf2iAE2N0LqYO6Yi_XNlcg)  
摘要：随着AI模型结构的快速演化，底层计算硬件的层出不穷，用户使用习惯的推陈出新，单纯基于手工优化来解决AI模型的性能和效率问题越来越容易出现瓶颈。为了应对这些问题，AI编译优化技术已经成为一个获得广泛关注的技术方向。这两年来，这个领域也异常地活跃，包括老牌一些的TensorFlow XLA、TVM、Tensor Comprehension、Glow，以及最近呼声很高的MLIR，能够看到不同的公司、社区在这个领域进行着大量的探索和推进。本文将会对AI编译优化技术领域发表PAI团队的理解。  
- [微信扫一扫识物技术的从0到1 | 微信AI](https://mp.weixin.qq.com/s/z9FTEqC6eQ9-WRbR1tobJg)  
摘要：前不久的首届广州直播节，用户只需打开手机微信的“扫一扫识物”扫描广州塔，即可进入广州直播节的小程序，直达一个72小时不打烊的“云购物天堂”。  
在这背后，是微信扫一扫识物技术从识别特定编码形态的图片如二维码/小程序码到精准识别自然场景中商品图片的巨大技术进步。它是如何实现的？过程中又有哪些难点需要克服？在未来又会催生哪些新的落地场景？我们用1万多字告诉你答案。  
- [如何在Jetson nano上编译带TensorRT的飞桨框架 | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s/MHmMiUQElL7OfXFSxSCNbQ)  
摘要：Jetson系列在GPU加速上效果相对更好。飞桨也对该系列的硬件支持较好。  
一方面可以通过百度针对终端发布的轻量化推理引擎PaddleLite进行部署，同时使用模型量化等操作加速推理；另一方面可以使用飞桨原生推理库Paddle Inference，通过调用Paddle-TensorRT接口，充分地利用Nvidia的软硬件资源。  
本文将展示如何通过源码编译的方式在Jetson nano上安装Paddle-Lite框架，并部署模型。  

> 注：个别链接打不开，请点击文末【阅读原文】跳转



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
| - | - | [2020-07-18](../embedded-ai-report/2020-07-18.md) | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
